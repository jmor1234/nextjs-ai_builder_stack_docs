# Integrating the Vercel AI SDK with Convex

## `components/ConvexClientProvider.tsx`

```typescript
"use client";

import { ConvexProvider, ConvexReactClient } from "convex/react";
import { ReactNode } from "react";

const convex = new ConvexReactClient(process.env.NEXT_PUBLIC_CONVEX_URL!);

export function ConvexClientProvider({ children }: { children: ReactNode }) {
  return <ConvexProvider client={convex}>{children}</ConvexProvider>;
}
```

## `app/layout.tsx`

```typescript
import "./globals.css";
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import { ConvexClientProvider } from "../components/ConvexClientProvider";

const inter = Inter({ subsets: ["latin"] });

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <body className={inter.className}>
        <ConvexClientProvider>{children}</ConvexClientProvider>
      </body>
    </html>
  );
}
```

## `app/page.tsx`

```typescript
'use client';

import { useChat } from 'ai/react';
import { useState, useRef, useEffect } from 'react';
import { Send, User, Bot, Moon, Sun } from 'lucide-react';

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    // this enables the connection to convex
    api: 'https://acrobatic-curlew-931.convex.site/api/chat',
  });

  return (
    <div>
    // Frontend Chat UI Would Go Here
    </div>
  );
}
```

## `convex/http.ts`

```typescript
import { Hono } from "hono";
import { HonoWithConvex, HttpRouterWithHono } from "convex-helpers/server/hono";
import { ActionCtx } from "./_generated/server";
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';
import { cors } from 'hono/cors'

const app: HonoWithConvex<ActionCtx> = new Hono();

app.use('/api/*', cors())

app.post("/api/chat", async (c) => {
    const { messages } = await c.req.json();

  const result = await streamText({
    model: openai('gpt-4-turbo'),
    messages,
  });

  return result.toDataStreamResponse();
});

const router = new HttpRouterWithHono(app);
export default router;
```